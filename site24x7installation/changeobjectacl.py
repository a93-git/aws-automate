""" Change the ACL of the SSM output written to the S3 bucket.

If account B sends its output to S3 bucket in account A, account A won't have 
any permissions on those files. We need to apply 'bucket-owner-full-control'
canned ACL to all such objects. 

SSM command doesn't have a method to specify the ACL for objects.

This function is invoked by SQS message

We need to set up the following environment variables for this function:
Role_ARN - The role in the account B to be assumed
External_Id - External ID to use when assuming role in account B

Attach the following policies to the execution role for this function:

TODO: Get all the required steps and IAM policies

"""
import boto3
import logging
import os
import time

logger = logging.getLogger()
logger.setLevel(logging.INFO)

role_arn = os.environ['Role_ARN']
external_id = os.environ['External_Id']

def get_temp_creds(role_arn, external_id):
    """ Retrieve temporary security credentials

    Arguments:
    role_arn - ARN of the AWS role to assume (in the customer's account)
    external_id - An alphanumeric string configured as an added security measure

    Return:
    Returns a tuple of access key, secret access key and session token
    """
    logger.info("Getting temporary access credentials for Role ARN {0}".format(role_arn))
    try:
        client_sts = boto3.client('sts')
        a = client_sts.assume_role(RoleSessionName='test-session', RoleArn=role_arn, DurationSeconds=900, ExternalId=external_id)
        access_key = a['Credentials']['AccessKeyId']
        secret_access_key = a['Credentials']['SecretAccessKey']
        session_token = a['Credentials']['SessionToken']
        return (access_key, secret_access_key, session_token)
    except Exception as e:
        logger.info("Error in getting temporary security credentials")
        logger.error(e)
        return (None, None, None)


def s3_put_object_acl(bucket_name, object_key, client_s3):
    """ Put canned ACL 'bucket-owner-full-control' to provide the Master account to have access to the log
    files generated by the SSM command

    Arguments:
    bucket_name - name of the bucket where the output is being stored
    object_key - object key for which we want to change the ACL (Note: the key should have all the prefixes)
    
    Return:
    None
    """
    logger.info("Changing ACL of: {0}".format(object_key))
    try:
        client_s3.put_object_acl(
            ACL='bucket-owner-full-control',
            Bucket=bucket_name,
            Key=object_key
        )
    except Exception as e:
        logger.info("Error in changing the ACL of the object {0} in bucket {1}".format(object_key, bucket_name))
        logger.error(e)


def fix_acl(value, client_s3):
    """ Attempts to fix the ACL

    Arguments:
    value - Record entry with the bucket and key details
    client_s3 - Interface to S3 service

    Return:
    None
    """

    _flow = False
    try:
        bucket_name = value['bucket_name']
        command_id = value['command_id']
        prefix = value['prefix']
        instance_id = value['instance_id']
        script_name = value['script_name']
        _flow = True
    except Exception as e:
        logger.info('Error in putting ACL')
        logger.info('Incomplete information')
        logger.error(e)
    
    if _flow:
        if 'AWS-RunPowerShellScript' in script_name:
            try:
                object_key_1 = prefix + '/' + command_id + '/' + instance_id + '/awsrunPowerShellScript/0.awsrunPowerShellScript/stdout'
                s3_put_object_acl(bucket_name, object_key_1, client_s3)
            except Exception as e:
                logger.info("Error in putting ACL for {0}".format(object_key_1))
                logger.error(e)
            try:
                object_key_2 = prefix + '/' + command_id + '/' + instance_id + '/awsrunPowerShellScript/0.awsrunPowerShellScript/stderr'
                s3_put_object_acl(bucket_name, object_key_2, client_s3)
            except Exception as e:
                logger.info("Error in putting ACL for {0}".format(object_key_2))
                logger.error(e)
        elif 'AWS-RunShellScript' in script_name:
            try:
                object_key_1 = prefix + '/' + command_id + '/' + instance_id + '/awsrunShellScript/0.awsrunShellScript/stdout'
                s3_put_object_acl(bucket_name, object_key_1, client_s3)
            except Exception as e:
                logger.info("Error in putting ACL for {0}".format(object_key_1))
                logger.error(e)
            try:
                object_key_2 = prefix + '/' + command_id + '/' + instance_id + '/awsrunShellScript/0.awsrunShellScript/stderr'
                s3_put_object_acl(bucket_name, object_key_2, client_s3)
            except Exception as e:
                logger.info("Error in putting ACL for {0}".format(object_key_2))
                logger.error(e) 
                    
def lambda_handler(event, context):
    _time = time.time()
    
    logger.info("Message is: {0}".format(event))
    creds = get_temp_creds(role_arn, external_id)

    if None in creds:
        logger.error("Security credentials couldn't be retrieved. Exiting...")
        exit()

    client_s3 = boto3.client('s3', 
        aws_access_key_id=creds[0], 
        aws_secret_access_key=creds[1], 
        aws_session_token=creds[2])

    for body in event['Records']:
        for message in eval(eval(body['body'])['Message']):
            if 'bucket_name' in message.keys() and 'command_id' in message.keys() and 'prefix' in message.keys() and 'instance_id' in message.keys() and 'script_name' in message.keys():
                fix_acl(message, client_s3)
            else:
                logger.info(message.keys())
                logger.error('Not all keys are present')
                
    logger.info("Time of execution: {0}s".format(time.time() - _time))